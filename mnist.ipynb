{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n",
      "total_batch=1200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tr = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('./data', download=True, train=True, transform=tr)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=50, shuffle=True)\n",
    "print(train_data)\n",
    "\n",
    "test_data = datasets.MNIST('./data', train=False, transform=tr)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=50, shuffle=True)\n",
    "\n",
    "\n",
    "total_batch = len(train_loader)\n",
    "print(f\"{total_batch=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 4, padding=1)\n",
    "        \n",
    "        self.norm1 = nn.BatchNorm2d(16)\n",
    "        self.norm2 = nn.BatchNorm2d(32)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.norm10 = nn.BatchNorm1d(128)\n",
    "        self.norm20 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc1 = nn.Linear(36 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.norm1(self.conv1(x)))\n",
    "        x = self.pool(self.norm2(F.relu(self.conv2(x))))\n",
    "        x = self.dropout(self.pool(self.norm3(F.relu(self.conv3(x)))))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "#         print(x.size())\n",
    "        x = F.relu(self.norm10(self.fc1(x)))\n",
    "        x = F.relu(self.dropout(self.norm20(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm20): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=2304, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = Net().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, threshold=0.01, patience=1, mode='min')   \n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 train_loss=16.215747833251953%\n",
      "Accuracy: 98.95%\n",
      "epoch=1 train_loss=3.9626197814941406%\n",
      "Accuracy: 98.52%\n",
      "epoch=2 train_loss=2.7247776985168457%\n",
      "Accuracy: 98.94%\n",
      "epoch=3 train_loss=1.9666361808776855%\n",
      "Accuracy: 99.17%\n",
      "epoch=4 train_loss=1.5548884868621826%\n",
      "Accuracy: 98.67%\n",
      "epoch=5 train_loss=1.3974908590316772%\n",
      "Accuracy: 98.96%\n",
      "epoch=6 train_loss=1.3099182844161987%\n",
      "Accuracy: 99.36%\n",
      "epoch=7 train_loss=0.9125514030456543%\n",
      "Accuracy: 99.16%\n",
      "epoch=8 train_loss=1.0905722379684448%\n",
      "Accuracy: 99.25%\n",
      "epoch=9 train_loss=0.7924409508705139%\n",
      "Accuracy: 99.08%\n",
      "epoch=10 train_loss=0.7038989663124084%\n",
      "Accuracy: 99.37%\n",
      "epoch=11 train_loss=0.17871232330799103%\n",
      "Accuracy: 99.5%\n",
      "epoch=12 train_loss=0.03924359381198883%\n",
      "Accuracy: 99.56%\n",
      "epoch=13 train_loss=0.016178198158740997%\n",
      "Accuracy: 99.53%\n",
      "epoch=14 train_loss=0.00799106527119875%\n",
      "Accuracy: 99.55%\n",
      "epoch=15 train_loss=0.004029366187751293%\n",
      "Accuracy: 99.54%\n",
      "epoch=16 train_loss=0.002108413726091385%\n",
      "Accuracy: 99.58%\n",
      "epoch=17 train_loss=0.001033838139846921%\n",
      "Accuracy: 99.58%\n",
      "epoch=18 train_loss=0.0005053801578469574%\n",
      "Accuracy: 99.58%\n",
      "epoch=19 train_loss=0.0002515690866857767%\n",
      "Accuracy: 99.57%\n",
      "train finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net.train()\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for x, target in train_loader:\n",
    "        x = x.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(x)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "    scheduler.step(loss) \n",
    "        \n",
    "    print(f\"{epoch=} train_loss={100 * total_loss / total_batch}%\")\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for (x, label) in test_loader:\n",
    "            x = x.to(device)\n",
    "            label = label.to(device)\n",
    "            output = net(x)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    print(f\"Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "torch.save(net.state_dict(), \"./mnist.pth\")\n",
    "print(\"train finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.57%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "net = Net().to(device)\n",
    "net.load_state_dict(torch.load(\"./mnist.pth\"))\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for (x, label) in test_loader:\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        output = net(x)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
